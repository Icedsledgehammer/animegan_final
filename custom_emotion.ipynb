{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a78d063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sad latents saved as sad.npy.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the Happy Latents (happy.npy)\n",
    "happy_latents = np.load(\"boundaries/boundary_happy.npy\")\n",
    "sad_latents = np.load(\"boundaries/boundary_sad.npy\")\n",
    "\n",
    "# Invert the Happy Latents to create Sad Latents\n",
    "angry_latent = sad_latent + (intensity * happy_latent)\n",
    "\n",
    "\n",
    "# Save the Sad Latents to a new file (sad.npy)\n",
    "np.save(\"boundaries/angry.npy\", sad_latents)\n",
    "\n",
    "print(\"✅ Sad latents saved as sad.npy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2c90f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Angry latents saved as angry.npy.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the Happy and Sad Latents\n",
    "happy_latents = np.load(\"boundaries/boundary_happy.npy\")\n",
    "sad_latents = np.load(\"boundaries/boundary_sad.npy\")\n",
    "\n",
    "# Compute Angry Latent by moving from Sad toward Happy\n",
    "intensity = 0.2  # Feel free to adjust this!\n",
    "angry_latent = sad_latents + (intensity * (happy_latents - sad_latents))\n",
    "\n",
    "# Save the Angry Latents to a new file\n",
    "np.save(\"boundaries/angry.npy\", angry_latent)\n",
    "\n",
    "print(\"✅ Angry latents saved as angry.npy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dd6414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as emotion_interpolation_grid.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def tensor2im(tensor):\n",
    "    if tensor.dim() == 4:\n",
    "        tensor = tensor[0]  # Take the first image in the batch\n",
    "    tensor = tensor.cpu().detach()\n",
    "    tensor = (tensor + 1.0) / 2.0  # Scale from [-1,1] to [0,1]\n",
    "    tensor = tensor.clamp(0, 1)\n",
    "    tensor = tensor.mul(255).byte()\n",
    "    array = tensor.permute(1, 2, 0).numpy()\n",
    "    return Image.fromarray(array)\n",
    "\n",
    "# Define intensities\n",
    "intensities = np.linspace(0.05, 0.3, 12)\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, intensity in enumerate(intensities):\n",
    "    # Interpolate between sad and happy latents\n",
    "    angry_latent = sad_latents + intensity * (happy_latents - sad_latents)  # shape: (18, 512)\n",
    "    angry_latent_tensor = torch.from_numpy(angry_latent).unsqueeze(0).float().to(DEVICE)  # shape: (1, 18, 512)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated, _ = encoder.decoder(angry_latent_tensor, input_is_latent=True, randomize_noise=False)\n",
    "        generated = encoder.face_pool(generated)\n",
    "        img = tensor2im(generated)  # tensor2im handles batch dim\n",
    "        img = img.resize((256, 256), Image.LANCZOS)\n",
    "\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"Intensity {intensity:.2f}\")\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"emotion_interpolation_grid.png\")\n",
    "print(\"Saved as emotion_interpolation_grid.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b5286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading e4e over the pSp framework from checkpoint: pretrained_models/e4e_ffhq_encode.pt\n",
      "Saved surprise_intensity_4.00.png\n",
      "Saved surprise_intensity_6.36.png\n",
      "Saved surprise_intensity_8.73.png\n",
      "Saved surprise_intensity_11.09.png\n",
      "Saved surprise_intensity_13.45.png\n",
      "Saved surprise_intensity_15.82.png\n",
      "Saved surprise_intensity_18.18.png\n",
      "Saved surprise_intensity_20.55.png\n",
      "Saved surprise_intensity_22.91.png\n",
      "Saved surprise_intensity_25.27.png\n",
      "Saved surprise_intensity_27.64.png\n",
      "Saved surprise_intensity_30.00.png\n",
      "Saved fear_intensity_4.00.png\n",
      "Saved fear_intensity_6.36.png\n",
      "Saved fear_intensity_8.73.png\n",
      "Saved fear_intensity_11.09.png\n",
      "Saved fear_intensity_13.45.png\n",
      "Saved fear_intensity_15.82.png\n",
      "Saved fear_intensity_18.18.png\n",
      "Saved fear_intensity_20.55.png\n",
      "Saved fear_intensity_22.91.png\n",
      "Saved fear_intensity_25.27.png\n",
      "Saved fear_intensity_27.64.png\n",
      "Saved fear_intensity_30.00.png\n",
      "Saved joy_intensity_4.00.png\n",
      "Saved joy_intensity_6.36.png\n",
      "Saved joy_intensity_8.73.png\n",
      "Saved joy_intensity_11.09.png\n",
      "Saved joy_intensity_13.45.png\n",
      "Saved joy_intensity_15.82.png\n",
      "Saved joy_intensity_18.18.png\n",
      "Saved joy_intensity_20.55.png\n",
      "Saved joy_intensity_22.91.png\n",
      "Saved joy_intensity_25.27.png\n",
      "Saved joy_intensity_27.64.png\n",
      "Saved joy_intensity_30.00.png\n",
      "Saved disbelief_intensity_4.00.png\n",
      "Saved disbelief_intensity_6.36.png\n",
      "Saved disbelief_intensity_8.73.png\n",
      "Saved disbelief_intensity_11.09.png\n",
      "Saved disbelief_intensity_13.45.png\n",
      "Saved disbelief_intensity_15.82.png\n",
      "Saved disbelief_intensity_18.18.png\n",
      "Saved disbelief_intensity_20.55.png\n",
      "Saved disbelief_intensity_22.91.png\n",
      "Saved disbelief_intensity_25.27.png\n",
      "Saved disbelief_intensity_27.64.png\n",
      "Saved disbelief_intensity_30.00.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from models.psp import pSp \n",
    "from utils.common import tensor2im  \n",
    "from argparse import Namespace\n",
    "\n",
    "# Setup device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pSp encoder\n",
    "def load_encoder(e4e_ckpt, device=DEVICE):\n",
    "    opts = Namespace(\n",
    "        checkpoint_path=e4e_ckpt,\n",
    "        device=device,\n",
    "        encoder_type='Encoder4Editing',\n",
    "        start_from_latent_avg=True,\n",
    "        input_nc=3,\n",
    "        n_styles=18,\n",
    "        stylegan_size=1024,\n",
    "        is_train=False,\n",
    "        learn_in_w=False,\n",
    "        output_size=1024,\n",
    "        id_lambda=0,\n",
    "        lpips_lambda=0,\n",
    "        l2_lambda=1,\n",
    "        w_discriminator_lambda=0,\n",
    "        use_w_pool=False,\n",
    "        w_pool_size=50,\n",
    "        use_ballholder_loss=False,\n",
    "        optim_type='adam',\n",
    "        batch_size=1,\n",
    "        resize_outputs=False\n",
    "    )\n",
    "    encoder = pSp(opts).to(device).eval()\n",
    "    return encoder\n",
    "\n",
    "# Load your pre-existing latent vectors\n",
    "happy_latents = np.load('boundaries/boundary_happy.npy')\n",
    "sad_latents = np.load('boundaries/boundary_sad.npy')\n",
    "angry_latents = np.load('boundaries/boundary_angry.npy')\n",
    "disgust_latents = np.load('boundaries/boundary_disgust.npy')\n",
    "sorrow_latents = np.load('boundaries/boundary_sorrow.npy')\n",
    "\n",
    "# Define intensities for blending\n",
    "intensities = np.linspace(4, 30, 12)\n",
    "\n",
    "# Generate new emotions by interpolating between existing ones\n",
    "new_emotions = {\n",
    "    \"surprise\": happy_latents + 0.2 * (angry_latents - happy_latents),\n",
    "    \"fear\": sad_latents + 0.3 * (angry_latents - sad_latents),\n",
    "    \"joy\": happy_latents + 0.15 * (disgust_latents - happy_latents),\n",
    "    \"disbelief\": sorrow_latents + 0.25 * (sad_latents - sorrow_latents)\n",
    "}\n",
    "\n",
    "# Load encoder (ensure the correct checkpoint path)\n",
    "e4e_checkpoint = \"pretrained_models/e4e_ffhq_encode.pt\"  \n",
    "encoder = load_encoder(e4e_checkpoint, device=DEVICE)\n",
    "\n",
    "# Generate and save emotion variations\n",
    "for i, (emotion, latent) in enumerate(new_emotions.items()):\n",
    "    for j, intensity in enumerate(intensities):\n",
    "        # Modify latent using intensity\n",
    "        emotion_latent = latent + intensity * (happy_latents - latent)  # Modify to suit your blend\n",
    "        \n",
    "        # Convert to torch tensor and process\n",
    "        emotion_latent_tensor = torch.from_numpy(emotion_latent).unsqueeze(0).float().to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated, _ = encoder.decoder(emotion_latent_tensor, input_is_latent=True, randomize_noise=False)\n",
    "            generated = encoder.face_pool(generated)\n",
    "            \n",
    "            # Ensure the tensor has the correct shape\n",
    "            generated = generated.squeeze(0)  # Remove batch dimension\n",
    "            img = tensor2im(generated).resize((256, 256), Image.LANCZOS)\n",
    "\n",
    "        # Save each emotion variation image as a separate PNG file\n",
    "        output_filename = f\"{emotion}_intensity_{intensity:.2f}.png\"\n",
    "        img.save(output_filename)\n",
    "        print(f\"Saved {output_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
